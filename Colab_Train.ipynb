{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "https://github.com/omid-sar/End_to_End_Transformer_En_Fa/blob/main/Colab_Train.ipynb",
      "authorship_tag": "ABX9TyMqSey0zRFTQtInrJO6C69V",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/omid-sar/End_to_End_Transformer_En_Fa/blob/main/Colab_Train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "TPzUp6abBocM"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/omid-sar/End_to_End_Transformer_En_Fa.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r8wBTBI3EQvB",
        "outputId": "03828c70-c27a-4e38-db4a-15d7c12f56f4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'End_to_End_Transformer_En_Fa'...\n",
            "remote: Enumerating objects: 291, done.\u001b[K\n",
            "remote: Counting objects: 100% (291/291), done.\u001b[K\n",
            "remote: Compressing objects: 100% (150/150), done.\u001b[K\n",
            "remote: Total 291 (delta 147), reused 236 (delta 96), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (291/291), 67.08 KiB | 11.18 MiB/s, done.\n",
            "Resolving deltas: 100% (147/147), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd End_to_End_Transformer_En_Fa"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "esKhktdpFogZ",
        "outputId": "ad445d99-1264-413b-ccba-1cea4ca3a844"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/End_to_End_Transformer_En_Fa\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#%%capture\n",
        "!pip install -r requirements.txt --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P6Mpi8SlMLFM",
        "outputId": "a7dde578-1d8a-4110-cfef-7b75e97bb2d8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/106.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.3/106.3 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.3/139.3 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.7/82.7 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m45.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.4/57.4 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.1/133.1 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m98.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m85.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m86.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m521.2/521.2 kB\u001b[0m \u001b[31m40.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m105.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.6/731.6 kB\u001b[0m \u001b[31m44.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m91.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m520.6/520.6 kB\u001b[0m \u001b[31m48.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m66.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m48.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m47.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m65.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m64.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m195.4/195.4 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m257.9/257.9 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.0/153.0 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m115.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m111.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m115.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m115.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m93.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m112.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m106.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m101.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m109.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m114.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m94.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m412.3/412.3 kB\u001b[0m \u001b[31m35.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.9/138.9 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.7/49.7 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.1/93.1 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m73.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m68.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.1/82.1 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m75.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for lit (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires openai, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ss8w4mANMqMO",
        "outputId": "ed9d56d3-ed92-42b0-b7b9-c754133cc080"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-02-16 14:52:16,101: INFO: utils: NumExpr defaulting to 2 threads.]\n",
            "2024-02-16 14:52:21.411156: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-02-16 14:52:21.411209: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-02-16 14:52:21.412535: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-02-16 14:52:21.419687: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-02-16 14:52:22.880900: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "[2024-02-16 14:52:25,531: INFO: main: \n",
            "\n",
            "x================================================================================x \n",
            "\n",
            ">>>>>> stage Data Ingestion stage started <<<<<<]\n",
            "[2024-02-16 14:52:25,543: INFO: common: yaml file: config/config.yaml loaded successfully]\n",
            "[2024-02-16 14:52:25,544: INFO: common: yaml file: params.yaml loaded successfully]\n",
            "[2024-02-16 14:52:25,562: INFO: common: created directory at: artifacts]\n",
            "[2024-02-16 14:52:25,562: INFO: common: created directory at: artifacts/data_ingestion]\n",
            "Downloading builder script: 100% 3.46k/3.46k [00:00<00:00, 18.4MB/s]\n",
            "Downloading readme: 100% 3.43k/3.43k [00:00<00:00, 18.0MB/s]\n",
            "Downloading data files:   0% 0/1 [00:00<?, ?it/s]\n",
            "Downloading data:   0% 0.00/16.4M [00:00<?, ?B/s]\u001b[A\n",
            "Downloading data:   0% 16.4k/16.4M [00:00<03:18, 82.5kB/s]\u001b[A\n",
            "Downloading data:   0% 61.4k/16.4M [00:00<01:37, 167kB/s] \u001b[A\n",
            "Downloading data:   1% 94.2k/16.4M [00:00<01:38, 166kB/s]\u001b[A\n",
            "Downloading data:   1% 209k/16.4M [00:00<00:49, 328kB/s] \u001b[A\n",
            "Downloading data:   3% 455k/16.4M [00:00<00:24, 654kB/s]\u001b[A\n",
            "Downloading data:   6% 946k/16.4M [00:01<00:12, 1.27MB/s]\u001b[A\n",
            "Downloading data:  12% 1.91M/16.4M [00:01<00:05, 2.44MB/s]\u001b[A\n",
            "Downloading data:  24% 3.85M/16.4M [00:01<00:02, 4.75MB/s]\u001b[A\n",
            "Downloading data:  36% 5.94M/16.4M [00:01<00:01, 6.56MB/s]\u001b[A\n",
            "Downloading data:  48% 7.89M/16.4M [00:01<00:01, 7.55MB/s]\u001b[A\n",
            "Downloading data:  61% 10.0M/16.4M [00:02<00:00, 8.48MB/s]\u001b[A\n",
            "Downloading data:  75% 12.2M/16.4M [00:02<00:00, 9.22MB/s]\u001b[A\n",
            "Downloading data: 100% 16.4M/16.4M [00:02<00:00, 6.26MB/s]\n",
            "Downloading data files: 100% 1/1 [00:05<00:00,  5.06s/it]\n",
            "Extracting data files: 100% 1/1 [00:00<00:00,  3.09it/s]\n",
            "Generating train split: 100% 612087/612087 [00:18<00:00, 33520.41 examples/s]\n",
            "Saving the dataset (1/1 shards): 100% 30604/30604 [00:00<00:00, 1693659.84 examples/s]\n",
            "[2024-02-16 14:52:54,155: INFO: data_ingestion: tep_en_fa_para downloaded and saved to artifacts/data_ingestion/data!]\n",
            "[2024-02-16 14:52:54,157: INFO: main: >>>>>> stage Data Ingestion stage completed <<<<<<\n",
            "\n",
            "x================================================================================x]\n",
            "[2024-02-16 14:52:54,157: INFO: main: >>>>>> stage Data Validation stage started <<<<<<]\n",
            "[2024-02-16 14:52:54,165: INFO: common: yaml file: config/config.yaml loaded successfully]\n",
            "[2024-02-16 14:52:54,166: INFO: common: yaml file: params.yaml loaded successfully]\n",
            "[2024-02-16 14:52:54,167: INFO: common: created directory at: artifacts]\n",
            "[2024-02-16 14:52:54,167: INFO: common: created directory at: artifacts/data_validation]\n",
            "[2024-02-16 14:52:54,167: INFO: data_validation: Found required file: state.json]\n",
            "[2024-02-16 14:52:54,167: INFO: data_validation: Found required file: dataset_info.json]\n",
            "[2024-02-16 14:52:54,167: INFO: data_validation: Found required file: data-00000-of-00001.arrow]\n",
            "[2024-02-16 14:52:54,167: INFO: data_validation: All required files are present.]\n",
            "[2024-02-16 14:52:54,168: INFO: main: >>>>>> stage Data Validation stage completed <<<<<<\n",
            "\n",
            "x================================================================================x]\n",
            "[2024-02-16 14:52:54,168: INFO: main: >>>>>> stage Data Transformation stage started <<<<<<]\n",
            "[2024-02-16 14:52:54,175: INFO: common: yaml file: config/config.yaml loaded successfully]\n",
            "[2024-02-16 14:52:54,176: INFO: common: yaml file: params.yaml loaded successfully]\n",
            "[2024-02-16 14:52:54,176: INFO: common: created directory at: artifacts]\n",
            "[2024-02-16 14:52:54,176: INFO: common: created directory at: artifacts/data_transformation]\n",
            "[2024-02-16 14:52:54,180: INFO: data_transformation: Dataset loaded from artifacts/data_ingestion/data.]\n",
            "[00:00:00] Pre-processing sequences                 ████████ 0        /        0\n",
            "\u001b[2K\u001b[1B\u001b[1A[00:00:00] Pre-processing sequences                 ████████ 2000     /        0\n",
            "\u001b[2K\u001b[1B\u001b[1A[00:00:00] Pre-processing sequences                 ████████ 4000     /        0\n",
            "\u001b[2K\u001b[1B\u001b[1A[00:00:00] Pre-processing sequences                 ████████ 6000     /        0\n",
            "\u001b[2K\u001b[1B\u001b[1A[00:00:00] Pre-processing sequences                 ████████ 8000     /        0\n",
            "\u001b[2K\u001b[1B\u001b[1A[00:00:00] Pre-processing sequences                 ████████ 10000    /        0\n",
            "\u001b[2K\u001b[1B\u001b[1A[00:00:00] Pre-processing sequences                 ████████ 12000    /        0\n",
            "\u001b[2K\u001b[1B\u001b[1A[00:00:00] Pre-processing sequences                 ████████ 14000    /        0\n",
            "\u001b[2K\u001b[1B\u001b[1A[00:00:00] Pre-processing sequences                 ████████ 16000    /        0\n",
            "\u001b[2K\u001b[1B\u001b[1A[00:00:00] Pre-processing sequences                 ████████ 18000    /        0\n",
            "\u001b[2K\u001b[1B\u001b[1A[00:00:00] Pre-processing sequences                 ████████ 20000    /        0\n",
            "\u001b[2K\u001b[1B\u001b[1A[00:00:01] Pre-processing sequences                 ████████ 22000    /        0\n",
            "\u001b[2K\u001b[1B\u001b[1A[00:00:01] Pre-processing sequences                 ████████ 24000    /        0\n",
            "\u001b[2K\u001b[1B\u001b[1A[00:00:01] Pre-processing sequences                 ████████ 26000    /        0\n",
            "\u001b[2K\u001b[1B\u001b[1A[00:00:01] Pre-processing sequences                 ████████ 28000    /        0\n",
            "\u001b[2K\u001b[1B\u001b[1A[00:00:01] Pre-processing sequences                 ████████ 30000    /        0\n",
            "\u001b[2K\u001b[1B\u001b[1A[00:00:01] Pre-processing sequences                 ████████ 0        /        0\n",
            "[00:00:00] Pre-processing sequences                 ████████ 0        /        0\n",
            "\u001b[2K\u001b[1B\u001b[1A[00:00:00] Pre-processing sequences                 ████████ 2000     /        0\n",
            "\u001b[2K\u001b[1B\u001b[1A[00:00:00] Pre-processing sequences                 ████████ 4000     /        0\n",
            "\u001b[2K\u001b[1B\u001b[1A[00:00:00] Pre-processing sequences                 ████████ 6000     /        0\n",
            "\u001b[2K\u001b[1B\u001b[1A[00:00:00] Pre-processing sequences                 ████████ 8000     /        0\n",
            "\u001b[2K\u001b[1B\u001b[1A[00:00:00] Pre-processing sequences                 ████████ 10000    /        0\n",
            "\u001b[2K\u001b[1B\u001b[1A[00:00:00] Pre-processing sequences                 ████████ 12000    /        0\n",
            "\u001b[2K\u001b[1B\u001b[1A[00:00:00] Pre-processing sequences                 ████████ 14000    /        0\n",
            "\u001b[2K\u001b[1B\u001b[1A[00:00:00] Pre-processing sequences                 ████████ 16000    /        0\n",
            "\u001b[2K\u001b[1B\u001b[1A[00:00:00] Pre-processing sequences                 ████████ 18000    /        0\n",
            "\u001b[2K\u001b[1B\u001b[1A[00:00:01] Pre-processing sequences                 ████████ 20000    /        0\n",
            "\u001b[2K\u001b[1B\u001b[1A[00:00:01] Pre-processing sequences                 ████████ 22000    /        0\n",
            "\u001b[2K\u001b[1B\u001b[1A[00:00:01] Pre-processing sequences                 ████████ 24000    /        0\n",
            "\u001b[2K\u001b[1B\u001b[1A[00:00:01] Pre-processing sequences                 ████████ 26000    /        0\n",
            "\u001b[2K\u001b[1B\u001b[1A[00:00:01] Pre-processing sequences                 ████████ 28000    /        0\n",
            "\u001b[2K\u001b[1B\u001b[1A[00:00:01] Pre-processing sequences                 ████████ 0        /        0\n",
            "[2024-02-16 14:52:59,236: INFO: data_transformation: Max length of source sentence: 37]\n",
            "[2024-02-16 14:52:59,236: INFO: data_transformation: Max length of target sentence: 33]\n",
            "[2024-02-16 14:52:59,254: INFO: stage_03_data_transformation: Data transformation stage completed and outputs saved.]\n",
            "[2024-02-16 14:52:59,254: INFO: main: >>>>>> stage Data Transformation stage completed <<<<<<\n",
            "\n",
            "x================================================================================x]\n",
            "[2024-02-16 14:52:59,254: INFO: main: >>>>>> stage Model Validation stage started <<<<<<]\n",
            "[2024-02-16 14:52:59,260: INFO: common: yaml file: config/config.yaml loaded successfully]\n",
            "[2024-02-16 14:52:59,261: INFO: common: yaml file: params.yaml loaded successfully]\n",
            "[2024-02-16 14:52:59,261: INFO: common: created directory at: artifacts]\n",
            "[2024-02-16 14:52:59,261: INFO: common: created directory at: artifacts/model_config]\n",
            "[2024-02-16 14:52:59,261: INFO: common: created directory at: artifacts/model_config/verification_info]\n",
            "[2024-02-16 14:52:59,319: INFO: model_utils: Using device: cuda]\n",
            "[2024-02-16 14:52:59,341: INFO: model_utils: Device name: Tesla T4]\n",
            "[2024-02-16 14:52:59,341: INFO: model_utils: Device memory: 14.75 GB]\n",
            "[2024-02-16 14:53:01,079: INFO: stage_04_model_verification: Model instantiation successful.]\n",
            "[2024-02-16 14:53:01,080: INFO: common: created directory at: artifacts/model_config/verification_info]\n",
            "[2024-02-16 14:53:01,082: INFO: model_utils: Model summary saved to artifacts/model_config/verification_info/verification_model_summary.txt]\n",
            "[2024-02-16 14:53:01,084: INFO: stage_04_model_verification: Model and device setup complete.]\n",
            "[2024-02-16 14:53:01,084: INFO: main: >>>>>> stage Model Validation stage completed <<<<<<\n",
            "\n",
            "x================================================================================x]\n",
            "[2024-02-16 14:53:01,084: INFO: main: >>>>>> stage Model Training stage started <<<<<<]\n",
            "[2024-02-16 14:53:01,084: INFO: model_utils: Using device: cuda]\n",
            "[2024-02-16 14:53:01,084: INFO: model_utils: Device name: Tesla T4]\n",
            "[2024-02-16 14:53:01,084: INFO: model_utils: Device memory: 14.75 GB]\n",
            "[2024-02-16 14:53:01,088: INFO: common: yaml file: config/config.yaml loaded successfully]\n",
            "[2024-02-16 14:53:01,089: INFO: common: yaml file: params.yaml loaded successfully]\n",
            "[2024-02-16 14:53:01,089: INFO: common: created directory at: artifacts]\n",
            "[2024-02-16 14:53:01,089: INFO: common: created directory at: artifacts/model_training]\n",
            "[2024-02-16 14:53:01,090: INFO: common: created directory at: artifacts/model_training/model_en_fa_weights]\n",
            "[2024-02-16 14:53:01,096: INFO: model_training: No model to preload, starting from scratch]\n",
            " Processing epoch 00: 100% 861/861 [02:36<00:00,  5.49it/s, loss=5.415]\n",
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: is he dead .\n",
            "    TARGET: آيا او مرده است .\n",
            " PREDICTED: اون .\n",
            "--------------------------------------------------------------------------------\n",
            "    SOURCE: if you think he can deal with death , then call for him , anders .\n",
            "    TARGET: آندرس ، اگر فكر مي‌كني كه او مي‌تواند . مردگان را زنده كند ، برو و تلفن كن .\n",
            " PREDICTED: تو بايد بايد به ما را .\n",
            "--------------------------------------------------------------------------------\n",
            "[2024-02-16 14:55:38,267: INFO: model_utils: Generated weights file path: artifacts/model_training/model_en_fa_weights/tmodel_00.pt]\n",
            "[2024-02-16 14:55:40,299: INFO: model_training:  Model saved in file path : artifacts/model_training/model_en_fa_weights/tmodel_00.pt]\n",
            "[2024-02-16 14:55:40,301: INFO: main: >>>>>> stage Model Training stage completed <<<<<<\n",
            "\n",
            "x================================================================================x]\n",
            "[2024-02-16 14:55:40,301: INFO: main: >>>>>> stage Model Evaluation stage started <<<<<<]\n",
            "[2024-02-16 14:55:40,301: ERROR: main: ModelEvaluationPipeline.__init__() missing 2 required positional arguments: 'tokenizer_src' and 'tokenizer_tgt']\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/End_to_End_Transformer_En_Fa/main.py\", line 66, in <module>\n",
            "    model_training = ModelEvaluationPipeline()\n",
            "TypeError: ModelEvaluationPipeline.__init__() missing 2 required positional arguments: 'tokenizer_src' and 'tokenizer_tgt'\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/End_to_End_Transformer_En_Fa/main.py\", line 71, in <module>\n",
            "    raise e \n",
            "  File \"/content/End_to_End_Transformer_En_Fa/main.py\", line 66, in <module>\n",
            "    model_training = ModelEvaluationPipeline()\n",
            "TypeError: ModelEvaluationPipeline.__init__() missing 2 required positional arguments: 'tokenizer_src' and 'tokenizer_tgt'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ewWqBURoWaf9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}